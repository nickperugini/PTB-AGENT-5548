# Generated by AIG Copilot - start

# PTB-AGENT-5548 Terraform Project

## Background
Currently, PTBs (Project Technical Briefs) must be created by hand, which can be time-consuming and repetitive. This project aims to speed up that process for very simple projects by enabling the use of agentic AI and automation tools to generate infrastructure and documentation quickly.

## Objective
- Decrease the time humans spend creating documentation (PTBs).
- Allow the development process to be sped up by removing tedious and repetitive tasks.
- Enable rapid prototyping and deployment for simple cloud projects.

## Scope
- **Global Application:** Designed to be used for projects in any AWS region.
- **Simple Projects:** Focused on straightforward use cases (basic Lambda, S3, DynamoDB, API Gateway).
- **Agentic AI Integration:** Leverages AI to automate infrastructure and documentation generation.
- **Extensible:** Can be expanded for more complex workflows as needed.

---

## Project Structure

- `main.tf`: Main Terraform configuration file. Defines the AWS provider, all resources, networking, permissions, and how everything is connected.
- `variables.tf`: Contains variable definitions for customizing the deployment (e.g., AWS region).
- `outputs.tf`: Specifies outputs such as API Gateway URLs and S3 bucket name for reference after deployment.
- `lambda/`: Directory containing the source code for the Lambda functions.
    - `lambda1/index.py`: Source code for Lambda 1.
    - `lambda2/index.py`: Source code for Lambda 2.
    - `lambda3/index.py`: Source code for Lambda 3.
    - `lambda4/index.py`: Source code for Lambda 4.

---

## Component Details

### 1. Lambda Functions

#### `lambda1` (Uploader Lambda)
- **Purpose:**
  - Writes a simple text file named `lambda1.txt` to the shared S3 bucket. The file content is `"Hello from lambda1"` (can be customized).
  - After uploading the file, it writes an item to the DynamoDB table with a partition key `"lambda1"` and a timestamp (the AWS request ID).
- **Typical Use Case:**
  - Demonstrates writing to both S3 and DynamoDB from a Lambda. The file content and DynamoDB item can be modified as needed.

#### `lambda2` (S3 Writer Lambda)
- **Purpose:**
  - Writes a text file named `lambda2.txt` to the shared S3 bucket. The file content is `"Hello from lambda1"` (can be customized in code).
- **Typical Use Case:**
  - Demonstrates writing to S3 from a Lambda. No DynamoDB interaction.

#### `lambda3` (S3 Writer Lambda)
- **Purpose:**
  - Writes a text file named `lambda3.txt` to the shared S3 bucket. The file content is `"Hello from lambda1"` (can be customized in code).
- **Typical Use Case:**
  - Demonstrates writing to S3 from a Lambda. No DynamoDB interaction.

#### `lambda4` (S3 Writer Lambda)
- **Purpose:**
  - Writes a text file named `lambda4.txt` to the shared S3 bucket. The file content is `"Hello from lambda1"` (can be customized in code).
- **Typical Use Case:**
  - Demonstrates writing to S3 from a Lambda. No DynamoDB interaction.

> **Note:** The current Lambda implementations for lambda2, lambda3, and lambda4 only write a text file to S3. They do not process S3 events, query DynamoDB, or perform cleanup. You can extend their logic as needed.

---

## Terraform Files

#### `main.tf`
- **Purpose:**
  - Central configuration for the AWS infrastructure.
  - Sets up the VPC, subnets, security groups, S3 bucket, DynamoDB table, IAM roles and policies, Lambda functions, and API Gateway HTTP APIs.
  - Packages each Lambda function as a zip file and deploys it.
  - Connects Lambda functions to API Gateway endpoints for invocation.
- **Typical Use Case:**
  - Run `terraform init` and `terraform apply` to deploy the infrastructure.

#### `variables.tf`
- **Purpose:**
  - Declares input variables for the Terraform configuration (e.g., AWS region).
  - Allows customization without editing the main configuration.
- **Typical Use Case:**
  - Edit this file or use a `.tfvars` file to change deployment parameters.

#### `outputs.tf`
- **Purpose:**
  - Outputs important resource identifiers after deployment, such as:
    - `api1_url`: URL for API Gateway 1 (routes to lambda1 and lambda2).
    - `api2_url`: URL for API Gateway 2 (routes to lambda3 and lambda4).
    - `bucket_name`: Name of the shared S3 bucket.
- **Typical Use Case:**
  - After running `terraform apply`, view these outputs for integration or testing.

---

## How to Use

1. **Initialize Terraform:**
   ```powershell
   # Generated by AIG Copilot - start
   terraform init
   # Generated by AIG Copilot - end
   ```
2. **Review and Customize Variables:**
   - Edit `variables.tf` or provide a `.tfvars` file as needed.
3. **Apply the Configuration:**
   ```powershell
   # Generated by AIG Copilot - start
   terraform apply
   # Generated by AIG Copilot - end
   ```
4. **Check Outputs:**
   - After deployment, review the outputs for API URLs and S3 bucket name.

---

## Notes
- Make sure you have AWS credentials configured before running Terraform.
- The Lambda function code can be modified in the respective `index.py` files under each `lambda` subdirectory.
- API Gateway endpoints are set up for each Lambda. You can invoke the Lambdas via HTTP GET requests to the provided URLs.
- The current Lambda code is simple and can be extended to add more logic (e.g., S3 event processing, DynamoDB queries, cleanup tasks).

# Generated by
